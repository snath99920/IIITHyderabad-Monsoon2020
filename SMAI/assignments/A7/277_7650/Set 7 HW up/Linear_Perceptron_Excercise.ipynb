{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Linear Perceptron Excercise.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwxWcO7fqb-L"
      },
      "source": [
        "# Excercise - Multi-class classification of MNIST using Perceptron"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcygblmOmQDZ"
      },
      "source": [
        "In binary perceptron, where $\\mathbf{y} \\in \\{-1, +1\\}$, we used to update our weights only for wrongly classified examples.\n",
        "\n",
        "The multi-class perceptron is regarded as a generalization of binary perceptron. Learning through iteration is the same as the perceptron. Weighted inputs are passed through a multiclass signum activation function. If the predicted output label is the same as true label then weights are not updated. However, when predicted output label $\\neq$ true label, then the wrongly classified input example is added to the weights of the correct label and subtracted from the weights of the incorrect label. Effectively, this amounts to ’rewarding’ the correct weight vector, ’punishing’ the misleading, incorrect weight\n",
        "vector, and leaving alone an other weight vectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pT8DgD1rhha3",
        "outputId": "326c2561-ecfe-4cfe-e123-02963376bcf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "!pip install gif"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gif\n",
            "  Downloading https://files.pythonhosted.org/packages/58/41/a556a028c7c04dba76ced9bbfb321ef63df48d50153d18291b433a3d9a89/gif-3.0.0.tar.gz\n",
            "Collecting Pillow>=7.1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/bf/92385b4262178ca22b34f82e0e09c2922eb351fe39f3cc7b8ba9ea555b41/Pillow-7.2.0-cp36-cp36m-manylinux1_x86_64.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2MB 2.6MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: gif\n",
            "  Building wheel for gif (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gif: filename=gif-3.0.0-cp36-none-any.whl size=4816 sha256=930c9c6e223f9a55bcb90fca4f91ed2e273e94553382d6c55a007cfd656a6e2f\n",
            "  Stored in directory: /root/.cache/pip/wheels/33/1a/03/e7ccc13d5cbed82b0fda53a7792dfe372cf8baf691601d78d1\n",
            "Successfully built gif\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: Pillow, gif\n",
            "  Found existing installation: Pillow 7.0.0\n",
            "    Uninstalling Pillow-7.0.0:\n",
            "      Successfully uninstalled Pillow-7.0.0\n",
            "Successfully installed Pillow-7.2.0 gif-3.0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUrOd7AjhWSd"
      },
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import numpy as np\n",
        "import seaborn as sns; sns.set();\n",
        "import pandas as pd\n",
        "import math\n",
        "import gif\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNkGLnbjTY-s"
      },
      "source": [
        "# Setting the seed to ensure reproducibility of experiments\n",
        "np.random.seed(11)\n",
        "\n",
        "# One-hot encoding of target label, Y\n",
        "def one_hot(a):\n",
        "  b = -1 * np.ones((a.size, a.max()+1))\n",
        "  b[np.arange(a.size), a] = 1\n",
        "  return b\n",
        "\n",
        "# Loading digits datasets\n",
        "digits = datasets.load_digits()\n",
        "\n",
        "# One-hot encoding of target label, Y\n",
        "Y = digits.target\n",
        "Y = one_hot(Y)\n",
        "\n",
        "# Adding column of ones to absorb bias b of the hyperplane into X\n",
        "X = digits.data\n",
        "bias_ones = np.ones((len(X), 1))\n",
        "X = np.hstack((X, bias_ones))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BPvc5P8KvrM",
        "outputId": "d4c0c2f0-3810-44f9-e9d5-09808357b159",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Train-val-test data\n",
        "X_train_val, X_test, Y_train_val, Y_test = train_test_split(X, Y, shuffle=True, test_size = 0.2)\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X_train_val, Y_train_val, test_size = 0.12517)\n",
        "\n",
        "print(\"Training dataset: \", X_train.shape)\n",
        "print(\"Validation dataset: \", X_val.shape)\n",
        "print(\"Test dataset: \", X_test.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training dataset:  (1257, 65)\n",
            "Validation dataset:  (180, 65)\n",
            "Test dataset:  (360, 65)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPJZdeDtUfoy",
        "outputId": "086581e6-455e-4cfc-868c-595026467e16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "sns.reset_orig();\n",
        "\n",
        "plt.gray()\n",
        "plt.matshow(digits.images[10])\n",
        "plt.show();"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2KVp57S1Zah"
      },
      "source": [
        "#### Write your code below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2ZGH4N7iX0U"
      },
      "source": [
        "def perceptron(X_train, Y_train, epochs, eta):\n",
        "  weights = np.zeros((X_train.shape[1], 1))\n",
        "  error = 1\n",
        "  epoch = 0\n",
        "  while(epoch < epochs and error != 0):\n",
        "    error = 0\n",
        "    y_hat = 0\n",
        "    for xi, yi in zip(X_train, Y_train):\n",
        "      if np.dot(weights.T, xi)[0] >= 0: \n",
        "        y_hat = 1\n",
        "      else: \n",
        "        y_hat = -1\n",
        "\n",
        "      if yi*y_hat < 0:\n",
        "        weights = (weights.T + yi*xi).T\n",
        "        error += 1\n",
        "\n",
        "    epoch += 1\n",
        "  return weights, error\n",
        "\n",
        "\n",
        "def predictClass(X_fit, Y_fit, weights):\n",
        "  pc = np.zeros(X_fit.shape[0])\n",
        "\n",
        "  for i in range(0, X_fit.shape[0]):\n",
        "    for j in range(0, Y_fit.shape[1]):\n",
        "      predict = np.dot(weights[:,j], X_fit[i,:])\n",
        "\n",
        "      if predict > 0:\n",
        "        pc[i] = j\n",
        "        break\n",
        "        \n",
        "  return pc"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cw7KO7sdhWSy"
      },
      "source": [
        "weights = np.zeros((X_train.shape[1], Y_train.shape[1]))\n",
        "\n",
        "for ob in range(Y_train.shape[1]):\n",
        "  w, error = perceptron(X_train, Y_train[:,ob], 100, 0.05)\n",
        "  weights[:,ob] = w[:,0]\n",
        "\n",
        "\n",
        "e_train = 0\n",
        "e_val = 0\n",
        "e_test = 0\n",
        "\n",
        "pc = predictClass(X_val, Y_val, weights)\n",
        "nsample_val = Y_val.shape[0]\n",
        "\n",
        "for i in range(0, nsample_val):\n",
        "  y_act = Y_val[i,:]\n",
        "\n",
        "  if y_act[int(pc[i])] != 1.0:\n",
        "    e_val += 1\n",
        "\n",
        "\n",
        "weights = np.zeros((X_train.shape[1], Y_train.shape[1]))\n",
        "\n",
        "for ob in range(Y_train.shape[1]):\n",
        "  w, error = perceptron(X_train, Y_train[:,ob], 100, 0.05)\n",
        "  weights[:,ob] = w[:,0]\n",
        "\n",
        "pc = predictClass(X_train, Y_train, weights)\n",
        "nsample_t = Y_train.shape[0]\n",
        "\n",
        "for i in range(0, nsample_t):\n",
        "  y_act = Y_train[i,:]\n",
        "\n",
        "  if y_act[int(pc[i])] != 1.0:\n",
        "    e_train += 1\n",
        "\n",
        "\n",
        "weights = np.zeros((X_test.shape[1], Y_test.shape[1]))\n",
        "\n",
        "for ob in range(Y_test.shape[1]):\n",
        "  w, error = perceptron(X_test, Y_test[:,ob], 100, 0.05)\n",
        "  weights[:,ob] = w[:,0]\n",
        "\n",
        "pc = predictClass(X_test, Y_test, weights)\n",
        "nsample_test = Y_test.shape[0]\n",
        "\n",
        "for i in range(0, nsample_test):\n",
        "  y_act = Y_test[i,:]\n",
        "\n",
        "  if y_act[int(pc[i])] != 1.0:\n",
        "    e_test += 1\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQlJlA4F3htQ",
        "outputId": "7dd9bf3f-d9cc-485a-ee81-5686891e8d93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(\"Validation Accuracy: \", (1-e_val/nsample_val)*100)\n",
        "print(\"Training Accuracy: \", (1-e_train/nsample_t)*100)\n",
        "print(\"Test Accuracy: \", (1-e_test/nsample_test)*100)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy:  91.11111111111111\n",
            "Training Accuracy:  92.76054097056483\n",
            "Test Accuracy:  97.77777777777777\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}